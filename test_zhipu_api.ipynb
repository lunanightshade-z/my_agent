{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a617971",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install zai-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369fb8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯Z.aiè®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼Œæˆ‘çš„è®¾è®¡ç›®çš„æ˜¯ä¸ºç”¨æˆ·æä¾›çŸ¥è¯†ã€å¸®åŠ©è§£å†³é—®é¢˜å¹¶é™ªä¼´äº¤æµã€‚æˆ‘èƒ½å¤Ÿå¤„ç†å„ç§é—®é¢˜ï¼Œä¾‹å¦‚æä¾›çŸ¥è¯†æ€§è§£é‡Šã€æä¾›å»ºè®®æˆ–è¯­è¨€æ”¯æŒã€‚å¦‚æœä½ æœ‰ä»€ä¹ˆéœ€æ±‚ï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘ï¼"
     ]
    }
   ],
   "source": [
    "from zai import ZhipuAiClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "zhipu_key = os.getenv(\"ZHIPU_API_KEY\")\n",
    "\n",
    "# åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
    "zhipu_client = ZhipuAiClient(api_key=zhipu_key)\n",
    "\n",
    "def get_zhipu_response(zhipu_client, question, thinking=\"disabled\"):\n",
    "    # åˆ›å»ºæµå¼æ¶ˆæ¯è¯·æ±‚\n",
    "    response = zhipu_client.chat.completions.create(\n",
    "        model=\"glm-4.7\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True,\n",
    "        extra_body={\"thinking\": {\n",
    "            \"type\": thinking\n",
    "        }\n",
    "    },\n",
    "    )\n",
    "\n",
    "    # å¤„ç†æµå¼å“åº”\n",
    "    full_content = \"\"\n",
    "    for chunk in response:\n",
    "        if not chunk.choices:\n",
    "            continue\n",
    "        \n",
    "        delta = chunk.choices[0].delta\n",
    "        \n",
    "        # å¤„ç†å¢é‡å†…å®¹\n",
    "        if hasattr(delta, 'content') and delta.content:\n",
    "            full_content += delta.content\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "    return full_content\n",
    "\n",
    "def get_zhipu_response_converse(zhipu_client, conversations, thinking=\"disabled\"):\n",
    "    # åˆ›å»ºæµå¼æ¶ˆæ¯è¯·æ±‚\n",
    "    response = zhipu_client.chat.completions.create(\n",
    "        model=\"glm-4.7\",\n",
    "        messages=conversations,\n",
    "        stream=True,\n",
    "        extra_body={\n",
    "            \"thinking\": {\n",
    "                    \"type\": thinking\n",
    "                }\n",
    "    },\n",
    "    )\n",
    "\n",
    "    # å¤„ç†æµå¼å“åº”\n",
    "    full_content = \"\"\n",
    "    for chunk in response:\n",
    "        if not chunk.choices:\n",
    "            continue\n",
    "        \n",
    "        delta = chunk.choices[0].delta\n",
    "        \n",
    "        # å¤„ç†å¢é‡å†…å®¹\n",
    "        if hasattr(delta, 'content') and delta.content:\n",
    "            full_content += delta.content\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "    return full_content\n",
    "\n",
    "\n",
    "conversations = []\n",
    "conversations.append({\"role\": \"user\", \"content\": \"ä½ æ˜¯è°\"})\n",
    "\n",
    "answer = get_zhipu_response_converse(zhipu_client, conversations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7b2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df72ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ğŸ’¡ å›ç­”:\n",
      "å¾®è°ƒå¤§æ¨¡å‹æ˜¯æŒ‡åœ¨ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹ï¼ˆBase Modelï¼Œå¦‚Llama 3ã€Qwenã€Baichuanç­‰ï¼‰ä¸Šï¼Œä½¿ç”¨ç‰¹å®šçš„é¢†åŸŸæ•°æ®è¿›è¡Œè¿›ä¸€æ­¥çš„è®­ç»ƒï¼Œä½¿å…¶åœ¨ç‰¹å®šä»»åŠ¡æˆ–é¢†åŸŸè¡¨ç°å¾—æ›´å‡ºè‰²ã€‚\n",
      "\n",
      "å¾®è°ƒçš„æ ¸å¿ƒé€»è¾‘æ˜¯ï¼š**åŸºç¡€æ¨¡å‹é€šæ™“â€œé€šè¯†â€ï¼Œå¾®è°ƒèµ‹äºˆæ¨¡å‹â€œä¸“ä¸šæŠ€èƒ½â€ã€‚**\n",
      "\n",
      "ä»¥ä¸‹æ˜¯å¾®è°ƒå¤§æ¨¡å‹çš„å…¨æµç¨‹æŒ‡å—ï¼Œä»å‡†å¤‡åˆ°è½åœ°ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬ä¸€æ­¥ï¼šæ˜ç¡®ç›®æ ‡ä¸é€‰æ‹©æ¨¡å‹\n",
      "\n",
      "åœ¨å¼€å§‹ä¹‹å‰ï¼Œä½ éœ€è¦æ¸…æ¥šä½ æƒ³è§£å†³ä»€ä¹ˆé—®é¢˜ï¼š\n",
      "*   **æ³¨å…¥æ–°çŸ¥è¯†ï¼š** æ•™æ¨¡å‹å…¬å¸å†…éƒ¨æ–‡æ¡£ã€åŒ»ç–—æ³•è§„ç­‰ï¼ˆéœ€æ³¨æ„å¹»è§‰é—®é¢˜ï¼‰ã€‚\n",
      "*   **æ”¹å˜è¯´è¯é£æ ¼ï¼š** è®©æ¨¡å‹æ‰®æ¼”ç‰¹å®šè§’è‰²ï¼ˆå¦‚è‹æ ¼æ‹‰åº•å¼æ•™å­¦ã€å®¢æœè¯æœ¯ï¼‰ã€‚\n",
      "*   **å­¦ä¹ ç‰¹å®šæŒ‡ä»¤ï¼š** è®©æ¨¡å‹æ›´å¥½åœ°éµå¾ªç‰¹å®šçš„JSONè¾“å‡ºæ ¼å¼æˆ–å¤æ‚çš„é€»è¾‘æŒ‡ä»¤ã€‚\n",
      "\n",
      "**é€‰æ‹©åŸºç¡€æ¨¡å‹ï¼š**\n",
      "*   **å¼€æºæ¨¡å‹ï¼š** Llama 3 (Meta)ã€Qwen (é˜¿é‡Œ)ã€Baichuan (ç™¾å·)ã€Mistralã€ChatGLM (æ™ºè°±)ã€‚\n",
      "    *   *å»ºè®®ï¼š* å¦‚æœä¸­æ–‡ä»»åŠ¡å¤šï¼Œé¦–é€‰ Qwen æˆ– Baichuanï¼›å¦‚æœè¿½æ±‚ç»¼åˆèƒ½åŠ›ï¼Œé¦–é€‰ Llama 3ã€‚\n",
      "*   **æ¨¡å‹å¤§å°ï¼š** æ˜¾å­˜æœ‰é™é€‰ 7B/8Bï¼›è¿½æ±‚æ•ˆæœä¸”èµ„æºå……è¶³é€‰ 14Bã€70B æˆ–æ›´å¤§ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬äºŒæ­¥ï¼šå‡†å¤‡æ•°æ® â€”â€” **æœ€é‡è¦çš„ä¸€ç¯**\n",
      "\n",
      "æ•°æ®çš„è´¨é‡ç›´æ¥å†³å®šäº†å¾®è°ƒçš„æ•ˆæœã€‚å¸¸è§çš„å¾®è°ƒæ•°æ®æ ¼å¼é€šå¸¸æ˜¯ **JSONL**ï¼Œæœ€æµè¡Œçš„æ˜¯ **Alpaca æ ¼å¼** æˆ– **ShareGPT æ ¼å¼**ã€‚\n",
      "\n",
      "#### 1. æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼ˆAlpacaæ ¼å¼ï¼‰\n",
      "```json\n",
      "{\n",
      "  \"instruction\": \"è§£é‡Šä¸€ä¸‹é‡å­çº ç¼ ã€‚\",\n",
      "  \"input\": \"\",\n",
      "  \"output\": \"é‡å­çº ç¼ æ˜¯é‡å­åŠ›å­¦ä¸­çš„ä¸€ç§ç°è±¡ï¼Œå…¶ä¸­ä¸¤ä¸ªæˆ–å¤šä¸ªç²’å­...\"\n",
      "}\n",
      "```\n",
      "\n",
      "#### 2. æ•°æ®æ„å»ºæ–¹æ³•\n",
      "*   **äººå·¥æ’°å†™ï¼š** è´¨é‡æœ€é«˜ï¼Œä½†æˆæœ¬é«˜ã€‚é€‚åˆéœ€è¦ç²¾å‡†è¾“å‡ºçš„åœºæ™¯ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€ç‰¹å®šæ ¼å¼ï¼‰ã€‚\n",
      "*   **åˆ©ç”¨ç°æœ‰å¤§æ¨¡å‹ç”Ÿæˆï¼š** è®© GPT-4 å¸®ä½ ç”Ÿæˆ Q&A å¯¹ï¼Œç„¶åäººå·¥æ¸…æ´—ã€‚\n",
      "*   **æ•°æ®è½¬æ¢ï¼š** å°†ç°æœ‰çš„æ•°æ®åº“ã€Wiki æ–‡æ¡£è½¬æ¢ä¸º QA å¯¹ã€‚\n",
      "*   **å…¬å¼€æ•°æ®é›†ï¼š** Hugging Face Datasetsã€é­”æ­ç¤¾åŒºç­‰ã€‚\n",
      "\n",
      "**é»„é‡‘æ³•åˆ™ï¼šåƒåœ¾è¿›ï¼Œåƒåœ¾å‡ºã€‚åŠ¡å¿…æ¸…æ´—æ•°æ®ï¼Œå»é™¤é‡å¤ã€é”™è¯¯å’Œæ•æ„Ÿä¿¡æ¯ã€‚**\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬ä¸‰æ­¥ï¼šé€‰æ‹©å¾®è°ƒæ–¹æ³•\n",
      "\n",
      "æ ¹æ®ä½ çš„æ˜¾å­˜å¤§å°ï¼ˆVRAMï¼‰å’Œéœ€æ±‚ï¼Œé€‰æ‹©ä¸åŒçš„å¾®è°ƒç­–ç•¥ï¼š\n",
      "\n",
      "#### 1. å…¨é‡å¾®è°ƒ\n",
      "*   **åŸç†ï¼š** æ›´æ–°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚\n",
      "*   **ä¼˜ç‚¹ï¼š** æ•ˆæœä¸Šé™æœ€é«˜ã€‚\n",
      "*   **ç¼ºç‚¹ï¼š** æå…¶æ¶ˆè€—æ˜¾å­˜ï¼ˆéœ€è¦å¤šå¼ A100/H800ï¼‰ï¼Œè®­ç»ƒæ…¢ã€‚\n",
      "\n",
      "#### 2. LoRA / QLoRA (ç›®å‰æœ€ä¸»æµ)\n",
      "*   **åŸç†ï¼š** å†»ç»“åŸæ¨¡å‹å‚æ•°ï¼Œåªåœ¨æ—è¾¹åŠ å°‘é‡çš„â€œé€‚é…å™¨â€å‚æ•°è¿›è¡Œè®­ç»ƒã€‚QLoRA ç»“åˆäº† 4-bit é‡åŒ–æŠ€æœ¯ã€‚\n",
      "*   **ä¼˜ç‚¹ï¼š** æå¤§é™ä½æ˜¾å­˜éœ€æ±‚ï¼ˆå•å¼ æ¶ˆè´¹çº§æ˜¾å¡å¦‚ RTX 3090/4090 å³å¯å¾®è°ƒ 7B æ¨¡å‹ï¼‰ï¼Œè®­ç»ƒå¿«ï¼Œæ¨¡å‹æ–‡ä»¶å°ã€‚\n",
      "*   **ç¼ºç‚¹ï¼š** æå…¶å¤æ‚ä»»åŠ¡çš„æ•ˆæœå¯èƒ½ç•¥é€Šäºå…¨é‡å¾®è°ƒï¼Œä½†åœ¨å¤§å¤šæ•°åœºæ™¯ä¸‹å·®è·æå°ã€‚\n",
      "\n",
      "**å»ºè®®ï¼š** ç»å¤§å¤šæ•°ä¸ªäººå’Œä¸­å°ä¼ä¸šå¼€å‘è€…é¦–é€‰ **QLoRA**ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬å››æ­¥ï¼šå¾®è°ƒå®æˆ˜ï¼ˆå·¥å…·ä¸æµç¨‹ï¼‰\n",
      "\n",
      "ç›®å‰æœ€æµè¡Œçš„å¼€æºå¾®è°ƒæ¡†æ¶æ˜¯ **LLaMA-Factory**ï¼ˆUIå‹å¥½ï¼ŒåŠŸèƒ½å…¨ï¼‰å’Œ **Unsloth**ï¼ˆé€Ÿåº¦å¿«ï¼Œä¸“é—¨é’ˆå¯¹Llamaï¼‰ã€‚\n",
      "\n",
      "#### ä»¥ LLaMA-Factory ä¸ºä¾‹çš„ç®€æ˜“æµç¨‹ï¼š\n",
      "\n",
      "1.  **å®‰è£…ç¯å¢ƒï¼š**\n",
      "    ```bash\n",
      "    git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
      "    cd LLaMA-Factory\n",
      "    pip install -r requirements.txt\n",
      "    ```\n",
      "\n",
      "2.  **æ³¨å†Œæ•°æ®ï¼š**\n",
      "    åœ¨ `data/dataset_info.json` ä¸­æ·»åŠ ä½ å‡†å¤‡å¥½çš„ JSONL æ–‡ä»¶è·¯å¾„ã€‚\n",
      "\n",
      "3.  **é…ç½®è®­ç»ƒå‚æ•°ï¼š**\n",
      "    *   **æ¨¡å‹åç§°ï¼š** å¦‚ `Qwen2.5-7B-Instruct`\n",
      "    *   **å¾®è°ƒæ–¹æ³•ï¼š** `lora`\n",
      "    *   **å­¦ä¹ ç‡ï¼š** å»ºè®® `5e-5` åˆ° `1e-4`\n",
      "    *   **Batch sizeï¼š** æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼ˆå¦‚ 4, 8, 16ï¼‰\n",
      "    *   **Epochsï¼š** é€šå¸¸ 3 åˆ° 5 è½®å³å¯ï¼Œè¿‡å¤šä¼šå¯¼è‡´è¿‡æ‹Ÿåˆã€‚\n",
      "\n",
      "4.  **å¼€å§‹è®­ç»ƒï¼š**\n",
      "    è¿è¡Œè®­ç»ƒè„šæœ¬ï¼Œå…³æ³¨ Lossï¼ˆæŸå¤±ï¼‰æ›²çº¿ã€‚Loss ä¸‹é™å¹¶å¹³ç¨³æ”¶æ•›å³ä»£è¡¨è®­ç»ƒæœ‰æ•ˆã€‚\n",
      "\n",
      "5.  **åˆå¹¶æ¨¡å‹ï¼š**\n",
      "    å°†è®­ç»ƒå¥½çš„ LoRA æƒé‡ä¸åŸå§‹æ¨¡å‹åˆå¹¶ï¼Œå¯¼å‡ºä¸€ä¸ªæ–°çš„å®Œæ•´æ¨¡å‹ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬äº”æ­¥ï¼šè¯„ä¼°ä¸æµ‹è¯•\n",
      "\n",
      "è®­ç»ƒå®Œä¸è¦æ€¥ç€ä¸Šçº¿ï¼Œå¿…é¡»è¿›è¡Œè¯„ä¼°ï¼š\n",
      "\n",
      "1.  **å®šæ€§è¯„ä¼°ï¼ˆè‚‰çœ¼è§‚æµ‹ï¼‰ï¼š**\n",
      "    *   åœ¨ Web UI ä¸­å’Œæ¨¡å‹å¯¹è¯ï¼Œçœ‹å›ç­”æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚\n",
      "    *   å¯¹æ¯” Base Modelï¼ˆæœªå¾®è°ƒå‰ï¼‰å’Œ Finetuned Modelï¼ˆå¾®è°ƒåï¼‰åœ¨åŒä¸€ä¸ªé—®é¢˜ä¸Šçš„å·®å¼‚ã€‚\n",
      "2.  **å®šé‡è¯„ä¼°ï¼ˆæ‰“åˆ†ï¼‰ï¼š**\n",
      "    *   ä½¿ç”¨æµ‹è¯•é›†è®¡ç®—å‡†ç¡®ç‡ã€BLEUåˆ†æ•°æˆ– ROUGEåˆ†æ•°ã€‚\n",
      "    *   ä½¿ç”¨è¯„ä¼°æ¡†æ¶å¦‚ **OpenCompass** æˆ– **Ragas**ã€‚\n",
      "3.  **å‰¯ä½œç”¨æ£€æŸ¥ï¼š**\n",
      "    *   **ç¾éš¾æ€§é—å¿˜ï¼š** æ¨¡å‹æ˜¯å¦å­¦ä¼šäº†æ–°çŸ¥è¯†ï¼Œä½†å¿˜äº†åŸæœ¬é€šç”¨çš„çŸ¥è¯†ï¼Ÿï¼ˆæ¯”å¦‚ç°åœ¨èƒ½å†™åŒ»ç–—æŠ¥å‘Šï¼Œä½†ä¸ä¼šå†™ Python for å¾ªç¯äº†ï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬å…­æ­¥ï¼šéƒ¨ç½²ä¸æ¨ç†\n",
      "\n",
      "å°†å¾®è°ƒå¥½çš„æ¨¡å‹éƒ¨ç½²ä¸Šçº¿ï¼š\n",
      "*   **æœ¬åœ°æµ‹è¯•ï¼š** ä½¿ç”¨ Ollama æˆ– LM Studio åŠ è½½ GGUF ç‰ˆæœ¬ã€‚\n",
      "*   **API æœåŠ¡ï¼š** ä½¿ç”¨ vLLM æˆ– TGI (Text Generation Inference) éƒ¨ç½²é«˜å¹¶å‘ API æ¥å£ã€‚\n",
      "*   **äº‘ç«¯éƒ¨ç½²ï¼š** AWSã€é˜¿é‡Œäº‘ PAIã€AutoDL ç­‰å¹³å°çš„ GPU å®ä¾‹ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### æ€»ç»“ï¼šå¾®è°ƒçš„æœ€ä½³å®è·µæ¸…å•\n",
      "\n",
      "1.  **æ•°æ®é‡ï¼š** å¹¶ä¸æ˜¯è¶Šå¤šè¶Šå¥½ã€‚å¯¹äº LoRAï¼Œå‡ ç™¾åˆ°å‡ ä¸‡æ¡é«˜è´¨é‡æ•°æ®å¾€å¾€è¶³ä»¥æ”¹å˜é£æ ¼æˆ–ç‰¹å®šä»»åŠ¡ã€‚\n",
      "2.  **è¿‡æ‹Ÿåˆï¼š** å¦‚æœæ¨¡å‹å¼€å§‹æ­»è®°ç¡¬èƒŒè®­ç»ƒé›†ï¼ˆä½†åœ¨æµ‹è¯•é›†è¡¨ç°å·®ï¼‰ï¼Œè¯´æ˜è®­ç»ƒè¿‡å¤´äº†ã€‚å‡å°‘ Epochs æˆ–å¢åŠ æ•°æ®ã€‚\n",
      "3.  **å­¦ä¹ ç‡ï¼š** å¤ªå¤§æ¨¡å‹ä¼šå‘æ•£ï¼ˆLoss çˆ†ç‚¸/NaNï¼‰ï¼Œå¤ªå°æ¨¡å‹å­¦ä¸åŠ¨ã€‚LoRA é€šå¸¸ç”¨å¤§ä¸€ç‚¹çš„å­¦ä¹ ç‡ï¼ˆ1e-4ï¼‰ã€‚\n",
      "4.  **Prompt è¿˜æ˜¯å¾®è°ƒï¼Ÿ** å¦‚æœåªæ˜¯æƒ³æ”¹ä¸ªè¯´è¯æ ¼å¼ï¼ŒPrompt Engineeringï¼ˆæç¤ºè¯å·¥ç¨‹ï¼‰å¤Ÿç”¨ï¼›å¦‚æœæ˜¯æƒ³æ³¨å…¥å¤§é‡é¢†åŸŸçŸ¥è¯†æˆ–é€»è¾‘ï¼Œå¿…é¡»å¾®è°ƒã€‚\n",
      "\n",
      "ç°åœ¨çš„å·¥å…·ï¼ˆå¦‚ LLaMA-Factoryï¼‰å·²ç»å°†é—¨æ§›é™å¾—éå¸¸ä½ï¼Œ**ä¸€å¼  RTX 4090 æ˜¾å¡ + ä¸€ä¸ªå‘¨æœ« + 1000æ¡ä¼˜è´¨æ•°æ®ï¼Œä½ å°±èƒ½æ‹¥æœ‰ä¸€ä¸ªå±äºè‡ªå·±çš„å¤§æ¨¡å‹ã€‚**"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from zai import ZhipuAiClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "zhipu_key = os.getenv(\"ZHIPU_API_KEY\")\n",
    "\n",
    "# åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
    "zhipu_client = ZhipuAiClient(api_key=zhipu_key)\n",
    "\n",
    "def get_zhipu_response(zhipu_client, question, thinking=\"disabled\"):\n",
    "    # åˆ›å»ºæµå¼æ¶ˆæ¯è¯·æ±‚\n",
    "    response = zhipu_client.chat.completions.create(\n",
    "        model=\"glm-4.7\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True,\n",
    "        extra_body={\"thinking\": {\n",
    "            \"type\": thinking\n",
    "        }\n",
    "    },\n",
    "    )\n",
    "\n",
    "    # å¤„ç†æµå¼å“åº”\n",
    "    full_content = \"\"\n",
    "    for chunk in response:\n",
    "        if not chunk.choices:\n",
    "            continue\n",
    "        \n",
    "        delta = chunk.choices[0].delta\n",
    "        \n",
    "        # å¤„ç†å¢é‡å†…å®¹\n",
    "        if hasattr(delta, 'content') and delta.content:\n",
    "            full_content += delta.content\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "    return full_content\n",
    "\n",
    "def get_zhipu_response_converse(zhipu_client, conversations, thinking=\"disabled\"):\n",
    "    # å¤„ç†æµå¼å“åº”\n",
    "    full_content = \"\"\n",
    "\n",
    "    # åˆ›å»ºæµå¼æ·±åº¦æ€è€ƒè¯·æ±‚\n",
    "    response = zhipu_client.chat.completions.create(\n",
    "        model=\"glm-4.7\",\n",
    "        messages=conversations,\n",
    "        extra_body={\n",
    "            \"thinking\": {\n",
    "                \"type\": thinking\n",
    "            }\n",
    "        },\n",
    "        stream=True,  # å¯ç”¨æµå¼è¾“å‡º\n",
    "        temperature=1.0\n",
    "    )\n",
    "\n",
    "    # å¤„ç†æµå¼å“åº”\n",
    "    reasoning_content = \"\"\n",
    "    thinking_phase = True\n",
    "\n",
    "    for chunk in response:\n",
    "        if not chunk.choices:\n",
    "            continue\n",
    "        \n",
    "        delta = chunk.choices[0].delta\n",
    "        \n",
    "        # å¤„ç†æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "        if hasattr(delta, 'reasoning_content') and delta.reasoning_content:\n",
    "            reasoning_content += delta.reasoning_content\n",
    "            if thinking_phase:\n",
    "                print(\"ğŸ§  æ€è€ƒä¸­...\", end=\"\", flush=True)\n",
    "                thinking_phase = False\n",
    "            print(delta.reasoning_content, end=\"\", flush=True)\n",
    "        \n",
    "        # å¤„ç†å›ç­”å†…å®¹\n",
    "        if hasattr(delta, 'content') and delta.content:\n",
    "            if thinking_phase:\n",
    "                print(\"\\n\\nğŸ’¡ å›ç­”:\")\n",
    "                thinking_phase = False\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "    return full_content\n",
    "\n",
    "\n",
    "conversations = []\n",
    "conversations.append({\"role\": \"user\", \"content\": \"å¦‚ä½•å¾®è°ƒå¤§æ¨¡å‹\"})\n",
    "\n",
    "answer = get_zhipu_response_converse(zhipu_client, conversations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a0fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  æ€è€ƒä¸­...ç”¨æˆ·æ­£åœ¨è¯¢é—®â€œHow to fine-tune a large modelâ€ï¼ˆå¦‚ä½•å¾®è°ƒå¤§æ¨¡å‹ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªå®½æ³›ä½†éå¸¸å®ç”¨çš„æŠ€æœ¯é—®é¢˜ã€‚æˆ‘éœ€è¦æä¾›ä¸€ä»½å…¨é¢ã€ç»“æ„åŒ–ä¸”æ˜“äºç†è§£çš„æŒ‡å—ã€‚\n",
      "\n",
      "**1. è§£æ„éœ€æ±‚ï¼š**\n",
      "*   **ç›®æ ‡ï¼š** å¤§æ¨¡å‹ï¼ˆLLMsï¼Œå¦‚ Llamaã€Qwenã€ChatGLM ç­‰ï¼‰ã€‚\n",
      "*   **åŠ¨ä½œï¼š** å¾®è°ƒï¼ˆPEFTã€SFTã€RLHF ç­‰ï¼‰ã€‚\n",
      "*   **ç›®æ ‡å—ä¼—ï¼š** å¯èƒ½æ˜¯å¯»æ±‚å®æ“æ­¥éª¤çš„ AI ç ”ç©¶äººå‘˜ã€å¼€å‘äººå‘˜æˆ–çˆ±å¥½è€…ã€‚æˆ‘åº”è¯¥æ¶µç›–ä»æ¦‚å¿µåˆ°æ‰§è¡Œçš„â€œæ˜¯ä»€ä¹ˆâ€ã€â€œä¸ºä»€ä¹ˆâ€ã€â€œæ€ä¹ˆåšâ€å’Œâ€œå·¥å…·â€ã€‚\n",
      "\n",
      "**2. æ„å»ºå›ç­”ç»“æ„ï¼š**\n",
      "åˆç†çš„æµç¨‹åº”è¯¥æ˜¯ï¼š\n",
      "*   **å¼•è¨€ï¼š** ä»€ä¹ˆæ˜¯å¾®è°ƒï¼Œä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ\n",
      "*   **å‡†å¤‡å·¥ä½œï¼š** åœ¨ç¼–å†™ä»£ç å‰ä½ éœ€è¦ä»€ä¹ˆï¼Ÿï¼ˆæ•°æ®ã€ç®—åŠ›ã€æ¨¡å‹ï¼‰ã€‚\n",
      "*   **æ–¹æ³•/æŠ€æœ¯ï¼š** å…¨é‡ vs. é«˜æ•ˆï¼ˆPEFT/LoRAï¼‰ã€‚è¿™å¯¹å¤§æ¨¡å‹è‡³å…³é‡è¦ã€‚\n",
      "*   **æµç¨‹ï¼ˆå®æ“ï¼‰ï¼š** åˆ†æ­¥æŒ‡å—ã€‚\n",
      "*   **å¸¸ç”¨å·¥å…·ï¼š** ä½¿ç”¨ä»€ä¹ˆæ¡†æ¶ï¼Ÿ\n",
      "*   **æœ€ä½³å®è·µ/æŠ€å·§ï¼š** å¦‚ä½•å–å¾—å¥½ç»“æœã€‚\n",
      "*   **æ€»ç»“ã€‚**\n",
      "\n",
      "**3. èµ·è‰å†…å®¹ - é€èŠ‚è¿›è¡Œï¼š**\n",
      "\n",
      "*   **å¼•è¨€ï¼š** ç®€è¦è§£é‡Šé¢„è®­ç»ƒæ¨¡å‹å¾ˆé€šç”¨ï¼Œä½†éœ€è¦ç‰¹å®šé¢†åŸŸçŸ¥è¯†æˆ–ç‰¹å®šé£æ ¼ã€‚å¾®è°ƒæ˜¯æ¡¥æ¢ã€‚\n",
      "\n",
      "*   **å‡†å¤‡å·¥ä½œï¼š**\n",
      "    *   *æ¨¡å‹ï¼š* é€‰æ‹©åŸºåº§ï¼ˆLlama 3, Mistral, Qwenï¼‰ã€‚æåŠåŸºåº§æ¨¡å‹ä¸ Instruct æ¨¡å‹çš„åŒºåˆ«ã€‚\n",
      "    *   *æ•°æ®ï¼š* æœ€å…³é”®çš„éƒ¨åˆ†ã€‚éœ€è¦é«˜è´¨é‡ã€‚æ ¼å¼é€šå¸¸ä¸º JSONLï¼ˆInstruction, Input, Outputï¼‰ã€‚æåŠæ•°æ®é›†æ¸…æ´—ã€‚\n",
      "    *   *ç®—åŠ›ï¼š* GPU æ˜¾å­˜ã€‚æåŠå¯¹äº LoRA ä¸€å¼  3090/4090 å°±è¶³å¤Ÿäº†ï¼Œä½†å…¨é‡å¾®è°ƒéœ€è¦ A100/H100 é›†ç¾¤ã€‚\n",
      "\n",
      "*   **å¾®è°ƒç­–ç•¥ï¼ˆæ ¸å¿ƒæŠ€æœ¯éƒ¨åˆ†ï¼‰ï¼š**\n",
      "    *   *å…¨é‡å¾®è°ƒï¼š* æ›´æ–°æ‰€æœ‰å‚æ•°ã€‚æ˜‚è´µï¼Œé™¤éæœ‰å¤§é‡æ•°æ®ï¼Œå¦åˆ™å¯èƒ½è¿‡æ‹Ÿåˆã€‚\n",
      "    *   *PEFTï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰ï¼š* è¿™æ˜¯ç°åœ¨çš„æ ‡å‡†ã€‚\n",
      "        *   *LoRA (Low-Rank Adaptation)ï¼š* å¿…é¡»è§£é‡Šã€‚æ·»åŠ ä½ç§©çŸ©é˜µã€‚\n",
      "        *   *QLoRAï¼š* é‡åŒ– + LoRAã€‚å¯¹äºæ¶ˆè´¹çº§æ˜¾å¡éå¸¸é‡è¦ã€‚\n",
      "        *   *P-tuning / Prefix Tuningï¼š* ç®€è¦æåŠä½œä¸ºæ›¿ä»£æ–¹æ¡ˆï¼Œä½† LoRA æ˜¯ç‹é“ã€‚\n",
      "\n",
      "*   **æµç¨‹ï¼ˆâ€œå¦‚ä½•åšâ€ï¼‰ï¼š**\n",
      "    1.  æ•°æ®å‡†å¤‡ï¼ˆæ¸…æ´—ã€æ ¼å¼åŒ–ï¼‰ã€‚\n",
      "    2.  ç¯å¢ƒæ­å»ºã€‚\n",
      "    3.  é…ç½®ï¼ˆè¶…å‚æ•°ï¼šå­¦ä¹ ç‡ã€batch sizeã€epochsï¼‰ã€‚\n",
      "    4.  è®­ç»ƒï¼ˆç›‘æ§ Lossï¼‰ã€‚\n",
      "    5.  è¯„ä¼°ï¼ˆåœ¨éªŒè¯é›†ä¸Šæµ‹è¯•ï¼‰ã€‚\n",
      "    6.  åˆå¹¶/å¯¼å‡ºï¼ˆå°†æƒé‡åˆå¹¶å›åŸºåº§æ¨¡å‹ï¼‰ã€‚\n",
      "\n",
      "*   **å·¥å…·/æ¡†æ¶ï¼š**\n",
      "    *   *Hugging Face:* Transformer, PEFT, BitsAndBytes (ç”¨äºé‡åŒ–)ã€‚\n",
      "    *   *é«˜å±‚å°è£…:* LLaMA-Factoryï¼ˆåœ¨ä¸­å›½éå¸¸æµè¡Œï¼‰ï¼ŒUnslothï¼ˆé€Ÿåº¦å¿«ï¼‰ï¼ŒAxolotlã€‚\n",
      "\n",
      "*   **å…³é”®å‚æ•°/è¶…å‚æ•°ï¼š**\n",
      "    *   *Learning Rate (å­¦ä¹ ç‡):* å¾ˆå° (2e-4 åˆ° 5e-5)ã€‚\n",
      "    *   *Batch Size (æ‰¹å¤§å°):* æ¢¯åº¦ç´¯ç§¯å…è®¸æ¯”æ˜¾å­˜æ”¯æŒæ›´å¤§çš„ batch sizeã€‚\n",
      "    *   *Epochs:* é€šå¸¸ 1-5 è¶³å¤Ÿç”¨äº SFTã€‚å¤šäº†ä¼šè¿‡æ‹Ÿåˆã€‚\n",
      "\n",
      "*   **å¸¸è§é™·é˜±ï¼ˆæœ€ä½³å®è·µï¼‰ï¼š**\n",
      "    *   æ•°æ®è´¨é‡ > æ•°é‡ã€‚\n",
      "    *   è¿‡æ‹Ÿåˆã€‚\n",
      "    *   å¹»è§‰ï¼ˆå¾®è°ƒä¸æ˜¯çŸ¥è¯†æ³¨å…¥çš„é­”æ³•æ£’ï¼ŒRAG æ›´é€‚åˆç‰¹å®šäº‹å®ï¼‰ã€‚\n",
      "\n",
      "**4. æ¶¦è‰²ä¸æ‰“ç£¨ï¼ˆèµ·è‰è¿‡ç¨‹ä¸­çš„è‡ªæˆ‘ä¿®æ­£ï¼‰ï¼š**\n",
      "*   *è¯­è¨€ï¼š* ä¸­æ–‡ï¼ˆæŒ‰è¦æ±‚ï¼‰ã€‚\n",
      "*   *è¯­è°ƒï¼š* ä¸“ä¸šä¸”æ˜“æ‡‚ã€‚ä½¿ç”¨è¦ç‚¹ç¬¦å·ä»¥æé«˜å¯è¯»æ€§ã€‚\n",
      "*   *é‡ç‚¹ï¼š* æˆ‘åº”è¯¥å¼ºè°ƒ **LoRA** å’Œ **QLoRA**ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å½“ä»Šç»å¤§å¤šæ•°ç‹¬ç«‹ç ”ç©¶äººå‘˜å’Œå…¬å¸é‡‡ç”¨çš„å®ç”¨æ–¹æ³•ã€‚é™¤éå¿…è¦ï¼Œå¦åˆ™ä¸è¦è¿‡å¤šçº ç»“äº Flash Attention çš„æ•°å­¦ç»†èŠ‚ã€‚\n",
      "*   *å…·ä½“å·¥å…·æ¨èï¼š* æ˜ç¡®æåŠ **LLaMA-Factory**ï¼Œå› ä¸ºå®ƒæœ‰å¾ˆå¥½çš„ Web UI ä¸”å¯¹ä¸­æ–‡æ”¯æŒå‹å¥½ã€‚æåŠ **Unsloth** æ˜¯ä¸ºäº†é€Ÿåº¦ã€‚\n",
      "\n",
      "**5. æœ€ç»ˆç»“æ„é¢„è§ˆï¼ˆæ„æ€å¤§çº²ï¼‰ï¼š**\n",
      "*   æ ‡é¢˜ï¼šå¾®è°ƒæŒ‡å—ã€‚\n",
      "*   1. æ ¸å¿ƒæ¦‚å¿µï¼ˆå…¨é‡ vs. PEFT/LoRAï¼‰ã€‚\n",
      "*   2. å‡†å¤‡å·¥ä½œï¼ˆç®—åŠ›ã€æ•°æ®ã€æ¨¡å‹ï¼‰ã€‚\n",
      "*   3. å…³é”®æŠ€æœ¯ã€‚\n",
      "*   4. åˆ†æ­¥æµç¨‹ã€‚\n",
      "*   5. å·¥å…·æ¨èã€‚\n",
      "*   6. ä½•æ—¶ä½¿ç”¨å¾®è°ƒ vs. RAG/Promptingã€‚\n",
      "\n",
      "**6. æ’°å†™å†…å®¹ï¼ˆå°†æ¦‚å¿µç¿»è¯‘æˆä¸­æ–‡ï¼‰ï¼š**\n",
      "*   *Full Fine-tuning* -> å…¨é‡å¾®è°ƒã€‚\n",
      "*   *PEFT* -> é«˜æ•ˆå‚æ•°å¾®è°ƒã€‚\n",
      "*   *LoRA* -> ä½ç§©è‡ªé€‚åº”ã€‚\n",
      "*   *SFT* -> ç›‘ç£å¾®è°ƒã€‚\n",
      "*   *Instruction Tuning* -> æŒ‡ä»¤å¾®è°ƒã€‚\n",
      "\n",
      "*ï¼ˆè‡ªæˆ‘ä¿®æ­£ï¼‰*ï¼šç¡®ä¿åŒºåˆ†åŸºåº§æ¨¡å‹å’Œ Instruct æ¨¡å‹ã€‚é€šå¸¸ï¼Œæœ€å¥½ä»åŸºåº§æ¨¡å‹è¿›è¡Œ SFTï¼Œæˆ–è€…ä» Instruct æ¨¡å‹å¼€å§‹ä»¥è·å¾—ç‰¹å®šè¡Œä¸ºã€‚æˆ‘ä¼šå»ºè®®ä½¿ç”¨åŸºåº§æ¨¡å‹ä½œä¸ºæ ‡å‡†ç”¨ä¾‹ã€‚\n",
      "\n",
      "**7. æœ€ç»ˆæ¶¦è‰²ï¼š** æ£€æŸ¥æ¸…æ™°åº¦ã€‚ç¡®ä¿æ˜ç¡®åŒºåˆ†*è®­ç»ƒ*å’Œ*æ¨ç†*ã€‚æåŠåœ¨è®­ç»ƒæ—¶éœ€è¦å…³æ³¨ Loss æ›²çº¿ã€‚\n",
      "\n",
      "**8. è¾“å‡ºç”Ÿæˆï¼š**ï¼ˆè¿™ä¸æä¾›çš„ä¼˜ç§€å›ç­”ç›¸ç¬¦ï¼‰ã€‚å¾®è°ƒå¤§æ¨¡å‹æ˜¯æŒ‡åœ¨ä¸€ä¸ªå·²ç»é¢„è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ Llama 3, Qwen, Mistral, Baichuan ç­‰ï¼‰ä¸Šï¼Œä½¿ç”¨ç‰¹å®šçš„é¢†åŸŸæ•°æ®è¿›ä¸€æ­¥è®­ç»ƒï¼Œä½¿å…¶å…·å¤‡ç‰¹å®šçš„èƒ½åŠ›ã€é£æ ¼æˆ–çŸ¥è¯†ã€‚\n",
      "\n",
      "ç›®å‰ä¸»æµçš„å¾®è°ƒæ–¹æ³•å·²ç»ä»æ—©æœŸçš„â€œå…¨é‡å¾®è°ƒâ€è½¬å‘äº†**å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰**ï¼Œç‰¹åˆ«æ˜¯ **LoRA** æŠ€æœ¯ã€‚\n",
      "\n",
      "ä»¥ä¸‹æ˜¯ä¸€ä»½è¯¦ç»†çš„å¤§æ¨¡å‹å¾®è°ƒå®æˆ˜æŒ‡å—ï¼Œåˆ†ä¸ºæ ¸å¿ƒæ¦‚å¿µã€å‡†å¤‡å·¥ä½œã€æŠ€æœ¯è·¯çº¿ã€æ“ä½œæ­¥éª¤å’Œå·¥å…·æ¨èäº”ä¸ªéƒ¨åˆ†ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ä¸€ã€ æ ¸å¿ƒæ¦‚å¿µï¼šé€‰æ‹©å“ªç§å¾®è°ƒæ–¹å¼ï¼Ÿ\n",
      "\n",
      "åœ¨å¼€å§‹ä¹‹å‰ï¼Œä½ éœ€è¦æ ¹æ®ä½ çš„æ˜¾å¡èµ„æºå’Œç›®æ ‡é€‰æ‹©ç­–ç•¥ï¼š\n",
      "\n",
      "1.  **å…¨é‡å¾®è°ƒ**\n",
      "    *   **åŸç†ï¼š** æ›´æ–°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚\n",
      "    *   **ç¼ºç‚¹ï¼š** æå…¶æ¶ˆè€—æ˜¾å­˜å’Œè®¡ç®—èµ„æºï¼Œå®¹æ˜“å¯¼è‡´æ¨¡å‹â€œç¾éš¾æ€§é—å¿˜â€ï¼ˆå¿˜æ‰äº†é¢„è®­ç»ƒçš„çŸ¥è¯†ï¼‰ã€‚\n",
      "    *   **é€‚ç”¨åœºæ™¯ï¼š** åªæœ‰æ‹¥æœ‰å¤§é‡ A100/H100 æ˜¾å¡é›†ç¾¤çš„å‚å•†æ‰ä¼šç”¨ã€‚\n",
      "\n",
      "2.  **PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰å‚æ•°é«˜æ•ˆå¾®è°ƒ â€”â€” â­ **æ¨è**\n",
      "    *   **åŸç†ï¼š** å†»ç»“åŸæ¨¡å‹çš„å¤§éƒ¨åˆ†å‚æ•°ï¼Œåªè®­ç»ƒæå°‘é‡çš„é¢å¤–å‚æ•°ã€‚\n",
      "    *   **LoRA (Low-Rank Adaptation)ï¼š** ç›®å‰æœ€æµè¡Œçš„æ–¹æ³•ã€‚åœ¨æ¨¡å‹åŸæœ‰çš„æƒé‡æ—æ—è·¯æ’å…¥ä¸¤ä¸ªä½ç§©çŸ©é˜µï¼Œåªè®­ç»ƒè¿™ä¸¤ä¸ªçŸ©é˜µã€‚æ˜¾å­˜å ç”¨æå°ï¼Œæ•ˆæœæ¥è¿‘å…¨é‡å¾®è°ƒã€‚\n",
      "    *   **QLoRA (Quantized LoRA)ï¼š** åœ¨ LoRA åŸºç¡€ä¸Šï¼Œå°†åŸæ¨¡å‹é‡åŒ–ä¸º 4-bit æˆ– 8-bitã€‚**è¿™ä½¿å¾—å•å¼ æ¶ˆè´¹çº§æ˜¾å¡ï¼ˆå¦‚ RTX 3090/4090ï¼‰å°±èƒ½å¾®è°ƒ 7B ç”šè‡³ 70B çš„æ¨¡å‹ã€‚**\n",
      "\n",
      "---\n",
      "\n",
      "### äºŒã€ å‡†å¤‡å·¥ä½œ\n",
      "\n",
      "ä½ éœ€è¦å‡†å¤‡ä¸‰æ ·ä¸œè¥¿ï¼šç®—åŠ›ã€æ•°æ®ã€åŸºåº§æ¨¡å‹ã€‚\n",
      "\n",
      "#### 1. ç®—åŠ›\n",
      "*   **æ¨¡å‹å¤§å°ä¸æ˜¾å­˜å»ºè®®ï¼ˆä½¿ç”¨ QLoRA + æ¢¯åº¦æ£€æŸ¥ç‚¹æŠ€æœ¯ï¼‰ï¼š**\n",
      "    *   **7B æ¨¡å‹ï¼š** éœ€è¦ ~12GB - 16GB æ˜¾å­˜ï¼ˆå¦‚ 3090, 4090, 4080ï¼‰ã€‚\n",
      "    *   **14B æ¨¡å‹ï¼š** éœ€è¦ ~24GB æ˜¾å­˜ï¼ˆå¦‚ 3090*2, 4090ï¼‰ã€‚\n",
      "    *   **70B æ¨¡å‹ï¼š** éœ€è¦ ~48GB+ æ˜¾å­˜ï¼ˆå¦‚ A100, 2x3090/4090ï¼‰ã€‚\n",
      "\n",
      "#### 2. æ•°æ®\n",
      "æ•°æ®è´¨é‡ç›´æ¥å†³å®šå¾®è°ƒæ•ˆæœã€‚\n",
      "*   **æ ¼å¼ï¼š** é€šå¸¸æ˜¯ JSONL æ ¼å¼ã€‚\n",
      "*   **å¸¸ç”¨ç»“æ„ï¼š**\n",
      "    *   **æŒ‡ä»¤å¾®è°ƒï¼š** `{\"instruction\": \"é—®é¢˜\", \"input\": \"ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰\", \"output\": \"å›ç­”\"}`\n",
      "    *   **å¯¹è¯å¾®è°ƒï¼š** `{\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}`\n",
      "*   **æ•°æ®é‡ï¼š** å¯¹äºå‚ç›´é¢†åŸŸï¼Œå‡ åƒæ¡åˆ°å‡ ä¸‡æ¡é«˜è´¨é‡æ•°æ®é€šå¸¸å°±è¶³å¤Ÿäº†ã€‚ä¸è¦ç”¨åƒåœ¾æ•°æ®å †ç Œã€‚\n",
      "\n",
      "#### 3. åŸºåº§æ¨¡å‹\n",
      "*   **Base vs Chatï¼š** å¦‚æœä½ æƒ³æ•™æ¨¡å‹æ–°çŸ¥è¯†æˆ–ç‰¹å®šé£æ ¼ï¼Œå°½é‡é€‰ **Base** æ¨¡å‹ã€‚å¦‚æœä½ åªæ˜¯æƒ³ä¼˜åŒ–å®ƒçš„å›ç­”æ–¹å¼ï¼Œä¹Ÿå¯ä»¥é€‰ **Chat** æ¨¡å‹ã€‚\n",
      "*   **å¼€æºé€‰æ‹©ï¼š** Llama 3, Qwen 2.5, Mistral, Yi, DeepSeek ç­‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ä¸‰ã€ å®æ“æ­¥éª¤\n",
      "\n",
      "ä»¥ä½¿ç”¨ **LoRA/QLoRA** ä¸ºä¾‹ï¼Œå¾®è°ƒæµç¨‹å¦‚ä¸‹ï¼š\n",
      "\n",
      "#### ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒæ­å»º\n",
      "ä½ éœ€è¦å®‰è£… Python å’Œç›¸å…³çš„æ·±åº¦å­¦ä¹ åº“ã€‚\n",
      "```bash\n",
      "pip install torch transformers datasets peft bitsandbytes trl accelerate\n",
      "```\n",
      "*   `transformers`: æ¨¡å‹æ ¸å¿ƒåº“ã€‚\n",
      "*   `peft`: å®ç° LoRA çš„åº“ã€‚\n",
      "*   `bitsandbytes`: ç”¨äºé‡åŒ–ï¼ˆ4bitåŠ è½½ï¼‰ã€‚\n",
      "*   `trl`: Hugging Face æä¾›çš„é«˜å±‚è®­ç»ƒåº“ï¼ˆåŒ…å« SFTTrainerï¼‰ã€‚\n",
      "\n",
      "#### ç¬¬äºŒæ­¥ï¼šåŠ è½½æ¨¡å‹ä¸é…ç½®\n",
      "ä½¿ç”¨ 4-bit åŠ è½½æ¨¡å‹ä»¥èŠ‚çœæ˜¾å­˜ï¼Œå¹¶é…ç½® LoRA å‚æ•°ã€‚\n",
      "\n",
      "```python\n",
      "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
      "from peft import LoraConfig\n",
      "\n",
      "# é‡åŒ–é…ç½®\n",
      "bnb_config = BitsAndBytesConfig(\n",
      "    load_in_4bit=True,\n",
      "    bnb_4bit_quant_type=\"nf4\",\n",
      "    bnb_4bit_compute_dtype=torch.float16,\n",
      ")\n",
      "\n",
      "# åŠ è½½æ¨¡å‹\n",
      "model = AutoModelForCausalLM.from_pretrained(\n",
      "    \"model_name\", \n",
      "    quantization_config=bnb_config,\n",
      "    device_map=\"auto\"\n",
      ")\n",
      "\n",
      "# LoRA é…ç½® (å…³é”®ï¼šåªè®­ç»ƒè¿™äº›å‚æ•°)\n",
      "peft_config = LoraConfig(\n",
      "    r=16,           # LoRA ç§©ï¼Œè¶Šå¤§å‚æ•°è¶Šå¤šï¼Œæ•ˆæœå¯èƒ½è¶Šå¥½ä½†è¶Šæ…¢\n",
      "    lora_alpha=32,  # ç¼©æ”¾å› å­\n",
      "    target_modules=[\"q_proj\", \"v_proj\"], # éœ€è¦å¾®è°ƒçš„æ¨¡å—ï¼ˆé€šå¸¸æ˜¯æ³¨æ„åŠ›å±‚ï¼‰\n",
      "    lora_dropout=0.05,\n",
      "    bias=\"none\",\n",
      "    task_type=\"CAUSAL_LM\"\n",
      ")\n",
      "```\n",
      "\n",
      "#### ç¬¬ä¸‰æ­¥ï¼šæ•°æ®å¤„ç†\n",
      "å°†ä½ çš„ JSONL æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹å¯ç†è§£çš„ Prompt æ ¼å¼ã€‚ä½ éœ€è¦å®šä¹‰ä¸€ä¸ªâ€œæ¨¡æ¿å‡½æ•°â€ï¼ŒæŠŠæ•°æ®æ‹¼æˆå­—ç¬¦ä¸²ï¼š\n",
      "> `<|start_header_id|>user<|end_header_id|>\\n\\nä½ å¥½<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nä½ å¥½å•Šï¼`\n",
      "\n",
      "#### ç¬¬å››æ­¥ï¼šå¼€å§‹è®­ç»ƒ\n",
      "ä½¿ç”¨ `SFTTrainer` (Supervised Fine-tuning Trainer) ç®€åŒ–ä»£ç ã€‚\n",
      "\n",
      "```python\n",
      "from trl import SFTTrainer\n",
      "\n",
      "trainer = SFTTrainer(\n",
      "    model=model,\n",
      "    train_dataset=dataset,\n",
      "    dataset_text_field=\"text\", # å¤„ç†å¥½çš„æ–‡æœ¬å­—æ®µ\n",
      "    peft_config=peft_config,\n",
      "    max_seq_length=512,        # æœ€å¤§åºåˆ—é•¿åº¦\n",
      "    args=TrainingArguments(\n",
      "        per_device_train_batch_size=4,\n",
      "        gradient_accumulation_steps=4,\n",
      "        learning_rate=2e-4,    # LoRA å­¦ä¹ ç‡é€šå¸¸æ¯”å…¨é‡å¤§\n",
      "        logging_steps=10,\n",
      "        num_train_epochs=3,\n",
      "        output_dir=\"./outputs\",\n",
      "    ),\n",
      ")\n",
      "\n",
      "trainer.train()\n",
      "```\n",
      "\n",
      "#### ç¬¬äº”æ­¥ï¼šä¿å­˜ä¸åˆå¹¶\n",
      "è®­ç»ƒç»“æŸåï¼Œä½ åªä¼šå¾—åˆ°ä¸€ä¸ªå‡ ç™¾ MB çš„ LoRA é€‚é…å™¨æ–‡ä»¶ã€‚\n",
      "*   **åŠ è½½æ–¹å¼ï¼š** æ¨ç†æ—¶ï¼Œåˆ†åˆ«åŠ è½½åŸºåº§æ¨¡å‹å’Œ LoRA æƒé‡ã€‚\n",
      "*   **åˆå¹¶ï¼š** ä½ å¯ä»¥å°† LoRA æƒé‡åˆå¹¶å›åŸºåº§æ¨¡å‹ï¼Œå¾—åˆ°ä¸€ä¸ªå®Œæ•´çš„ `.safetensors` æ¨¡å‹æ–‡ä»¶ï¼Œæ–¹ä¾¿éƒ¨ç½²ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### å››ã€ å¸¸ç”¨å·¥å…·æ¡†æ¶ï¼ˆæ¨èï¼‰\n",
      "\n",
      "å¦‚æœä½ ä¸æƒ³æ‰‹å†™ä¸Šé¢çš„ Python ä»£ç ï¼Œå¯ä»¥ä½¿ç”¨å°è£…å¥½çš„å·¥å…·ï¼Œæå¤§åœ°é™ä½é—¨æ§›ï¼š\n",
      "\n",
      "1.  **LLaMA-Factory** â­â­â­â­â­\n",
      "    *   **ç‰¹ç‚¹ï¼š** ç›®å‰æœ€ç«çš„å¾®è°ƒå·¥å…·ï¼Œæ”¯æŒ WebUI é¡µé¢æ“ä½œã€‚æ”¯æŒ Llama, Qwen, Baichuan ç­‰å‡ ä¹æ‰€æœ‰ä¸»æµæ¨¡å‹ã€‚æ”¯æŒ LoRA, QLoRA, å…¨é‡å¾®è°ƒã€‚\n",
      "    *   **é€‚ç”¨ï¼š** 95% çš„ä¸ªäººå¼€å‘è€…å’Œä¸­å°ä¼ä¸šã€‚æ— éœ€å†™ä»£ç ï¼Œé€šè¿‡é…ç½® YAML æ–‡ä»¶æˆ–ç‚¹å‡»é¼ æ ‡å³å¯è®­ç»ƒã€‚\n",
      "\n",
      "2.  **Unsloth**\n",
      "    *   **ç‰¹ç‚¹ï¼š** ä¸“é—¨ä¼˜åŒ–äº† Llama/Mistral çš„è®­ç»ƒé€Ÿåº¦ï¼Œæ˜¾å­˜å ç”¨æ›´ä½ï¼Œè®­ç»ƒé€Ÿåº¦æ¯” Hugging Face åŸç”Ÿå¿« 2 å€ä»¥ä¸Šã€‚\n",
      "    *   **é€‚ç”¨ï¼š** è¿½æ±‚è®­ç»ƒæ•ˆç‡ï¼Œä½¿ç”¨å•å¼ æ˜¾å¡çš„ç”¨æˆ·ã€‚\n",
      "\n",
      "3.  **Firefly**\n",
      "    *   **ç‰¹ç‚¹ï¼š** ä¸­æ–‡ç¤¾åŒºç»´æŠ¤è¾ƒå¥½ï¼Œæ”¯æŒå¤šè½®å¯¹è¯è®­ç»ƒï¼ŒæŒ‡ä»¤é›†ä¸°å¯Œã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### äº”ã€ é¿å‘æŒ‡å—ä¸æœ€ä½³å®è·µ\n",
      "\n",
      "1.  **æ•°æ®æ¸…æ´—æœ€é‡è¦ï¼š**\n",
      "    *   å»é™¤é‡å¤æ•°æ®ã€HTML æ ‡ç­¾ã€ä¹±ç ã€‚\n",
      "    *   å¦‚æœæ˜¯è®­ç»ƒç‰¹å®šé¢†åŸŸçš„é—®ç­”ï¼Œä¿è¯ `Output` çš„å›ç­”ä¸“ä¸šã€å‡†ç¡®ã€‚\n",
      "    *   *ä¸è¦*åŒ…å«çŸ›ç›¾çš„ä¿¡æ¯ã€‚\n",
      "\n",
      "2.  **é˜²æ­¢è¿‡æ‹Ÿåˆï¼š**\n",
      "    *   å¦‚æœè®­ç»ƒé›† Loss é™å¾—å¾ˆä½ï¼Œä½†éªŒè¯é›† Loss ä¸Šå‡ï¼ˆæˆ–è€…å®é™…å›ç­”å˜å·®ï¼‰ï¼Œè¯´æ˜æ¨¡å‹â€œèƒŒâ€ä¸‹æ¥äº†ï¼Œè€Œä¸æ˜¯â€œå­¦â€ä¼šäº†ã€‚\n",
      "    *   è§£å†³åŠæ³•ï¼šå‡å°‘ `epochs`ï¼ˆé€šå¸¸ 2-3 è¶³å¤Ÿï¼‰ï¼Œå¢åŠ æ•°æ®é‡ï¼Œä½¿ç”¨æ—©åœã€‚\n",
      "\n",
      "3.  **å­¦ä¹ ç‡ï¼š**\n",
      "    *   LoRA çš„å­¦ä¹ ç‡é€šå¸¸åœ¨ `1e-4` åˆ° `5e-4` ä¹‹é—´ï¼Œæ¯”å…¨é‡å¾®è°ƒï¼ˆ`1e-6`ï¼‰è¦å¤§å¾ˆå¤šã€‚\n",
      "\n",
      "4.  **å¾®è°ƒä¸æ˜¯ä¸‡èƒ½çš„ï¼š**\n",
      "    *   **æ³¨å…¥çŸ¥è¯†ï¼š** å¾®è°ƒé€‚åˆæ³¨å…¥é£æ ¼ã€æ ¼å¼ã€é€»è¾‘æ¨ç†æ–¹å¼å’Œé¢†åŸŸæœ¯è¯­ã€‚ä½†å¦‚æœéœ€è¦æ¨¡å‹çŸ¥é“å®æ—¶æ–°é—»æˆ–é•¿å°¾å†·çŸ¥è¯†ï¼Œ**RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)** æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚\n",
      "    *   **å¹»è§‰é—®é¢˜ï¼š** å¾®è°ƒæœ‰æ—¶ä¼šåŠ é‡å¤§æ¨¡å‹çš„èƒ¡è¯´å…«é“ï¼Œéœ€è¦é…åˆé«˜è´¨é‡æ•°æ®æ§åˆ¶ã€‚\n",
      "\n",
      "### æ€»ç»“æµç¨‹å›¾\n",
      "\n",
      "```text\n",
      "ç¡®å®šç›®æ ‡ -> å‡†å¤‡é«˜è´¨é‡æ•°æ® (JSONL) -> é€‰æ‹©åŸºåº§æ¨¡å‹ (å¦‚ Qwen-7B)\n",
      "     â†“\n",
      "é€‰æ‹©å·¥å…· (æ¨è LLaMA-Factory) -> é…ç½®å‚æ•° (LoRA, QLoRA) -> å¼€å§‹è®­ç»ƒ\n",
      "     â†“\n",
      "ç›‘æ§ Loss æ›²çº¿ -> æµ‹è¯•æ¨¡å‹æ•ˆæœ -> å¯¼å‡ºæƒé‡ -> éƒ¨ç½²åº”ç”¨\n",
      "```"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "conversations = []\n",
    "conversations.append({\"role\": \"user\", \"content\": \"å¦‚ä½•å¾®è°ƒå¤§æ¨¡å‹\"})\n",
    "\n",
    "answer = get_zhipu_response_converse(zhipu_client, conversations, thinking=\"enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd86d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5834f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9874600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e42615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d789020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  æ€è€ƒä¸­...1.  **ç†è§£ç›®æ ‡ï¼š** ç”¨æˆ·æƒ³è¦ä¸€ä¸ªç”µå•†æ¨èç³»ç»Ÿçš„æ¶æ„è®¾è®¡ã€‚å…³é”®è¦æ±‚åŒ…æ‹¬è€ƒè™‘ç”¨æˆ·è¡Œä¸ºã€å•†å“ç‰¹å¾å’Œå®æ—¶æ€§ã€‚\n",
      "\n",
      "2.  **è¯†åˆ«ç”µå•†æ¨èç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼š**\n",
      "    *   **æ•°æ®æºï¼š** ç”¨æˆ·è¡Œä¸ºï¼ˆç‚¹å‡»ã€è´­ä¹°ï¼‰ã€å•†å“ç‰¹å¾ï¼ˆç±»ç›®ã€ä»·æ ¼ã€å›¾ç‰‡ï¼‰ã€ä¸Šä¸‹æ–‡ï¼ˆæ—¶é—´ã€è®¾å¤‡ï¼‰ã€‚\n",
      "    *   **æ•°æ®å¤„ç†ï¼š** æ¸…æ´—ã€ç‰¹å¾å·¥ç¨‹ã€åµŒå…¥ã€‚\n",
      "    *   **ç®—æ³•/æ¨¡å‹ï¼š** å¬å›ï¼ˆç­›é€‰ï¼‰ã€æ’åï¼ˆæ’åºï¼‰ã€é‡æ’ï¼ˆä¸šåŠ¡é€»è¾‘ï¼‰ã€‚\n",
      "    *   **åŸºç¡€è®¾æ–½ï¼š** ç¦»çº¿å¤„ç†ï¼ˆæ‰¹å¤„ç†ï¼‰ã€è¿‘çº¿å¤„ç†ï¼ˆæµå¤„ç†ï¼‰ã€åœ¨çº¿æœåŠ¡ï¼ˆä½å»¶è¿Ÿï¼‰ã€‚\n",
      "    *   **è¯„ä¼°/åé¦ˆé—­ç¯ï¼š** A/B æµ‹è¯•ã€æŒ‡æ ‡ç›‘æ§ã€‚\n",
      "\n",
      "3.  **æ„å»ºå›ç­”ç»“æ„ï¼š** ä¸€ä¸ªå¥½çš„æ¶æ„è§£é‡Šéœ€è¦é€»è¾‘æµç•…ã€‚æˆ‘å°†ä½¿ç”¨ä»¥ä¸‹ç»“æ„ï¼š\n",
      "    *   **æ¦‚è¿°/é«˜å±‚æ¶æ„ï¼š** å›¾å½¢åŒ–æè¿°ï¼ˆæ€ç»´ä¸Šæˆ–æ–‡å­—ä¸Šï¼‰çš„å„å±‚çº§ï¼ˆæ•°æ®å±‚ã€è®¡ç®—å±‚ã€æœåŠ¡å±‚ï¼‰ã€‚\n",
      "    *   **è¯¦ç»†å±‚çº§åˆ†è§£ï¼š**\n",
      "        *   æ•°æ®å±‚ï¼ˆæ—¥å¿—ã€æ•°æ®åº“ã€ç‰¹å¾å­˜å‚¨ï¼‰ã€‚\n",
      "        *   å¬å›å±‚ï¼ˆå¤šè·¯å¬å›ï¼‰ã€‚\n",
      "        *   æ’åºå±‚ï¼ˆç²—æ’ -> ç²¾æ’ï¼‰ã€‚\n",
      "        *   é‡æ’å±‚ï¼ˆå¤šæ ·æ€§ã€è§„åˆ™ï¼‰ã€‚\n",
      "        *   æœåŠ¡å±‚ï¼ˆAPIã€ç¼“å­˜ï¼‰ã€‚\n",
      "    *   **è§£å†³å…·ä½“éœ€æ±‚ï¼š**\n",
      "        *   ç”¨æˆ·è¡Œä¸ºã€‚\n",
      "        *   å•†å“ç‰¹å¾ã€‚\n",
      "        *   å®æ—¶æ€§è¦æ±‚ï¼ˆè¿™æ˜¯åŒºåˆ†â€œç°ä»£â€ä¸â€œä¼ ç»Ÿâ€ç³»ç»Ÿçš„å…³é”®ï¼‰ã€‚\n",
      "    *   **æŠ€æœ¯æ ˆç¤ºä¾‹ï¼š** æåŠå…·ä½“å·¥å…·ã€‚\n",
      "    *   **è¯„ä¼°ä¸è¿­ä»£ï¼š** å¦‚ä½•æ”¹è¿›ã€‚\n",
      "\n",
      "4.  **èµ·è‰å†…å®¹ - é€èŠ‚è¿›è¡Œï¼š**\n",
      "\n",
      "    *   **å¼•è¨€ï¼š** å®šä¹‰ç›®æ ‡ï¼ˆå¢åŠ  GMVã€è½¬åŒ–ç‡ã€ç”¨æˆ·ç²˜æ€§ï¼‰ã€‚\n",
      "\n",
      "    *   **æ¶æ„å›¾ï¼ˆæ–‡å­—æè¿°ï¼‰ï¼š**\n",
      "        *   ç”¨æˆ·è¡Œä¸º -> å®¢æˆ·ç«¯/API ç½‘å…³ã€‚\n",
      "        *   æ—¥å¿—æ”¶é›† -> Kafka/Flinkã€‚\n",
      "        *   ç¦»çº¿æ•°æ®æ¹– (Hadoop/Hive)ã€‚\n",
      "        *   è®­ç»ƒ -> TensorFlow/PyTorch/XGBoostã€‚\n",
      "        *   æ¨¡å‹æœåŠ¡ -> Redis/å‘é‡æ•°æ®åº“ã€‚\n",
      "\n",
      "    *   **ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®å±‚ï¼ˆåŸºç¡€ï¼‰ï¼š**\n",
      "        *   *ç”¨æˆ·ç”»åƒï¼š* IDã€äººå£ç»Ÿè®¡å­¦ã€é•¿æœŸå…´è¶£ï¼ˆç¦»çº¿ï¼‰ã€çŸ­æœŸå…´è¶£ï¼ˆå®æ—¶/ä¼šè¯ï¼‰ã€‚\n",
      "        *   *å•†å“ç”»åƒï¼š* IDã€æ ‡é¢˜ã€å‘é‡åµŒå…¥ï¼ˆæ¥è‡ª CNN/Transformerï¼‰ã€ä»·æ ¼ã€åº“å­˜ã€‚\n",
      "        *   *è¡Œä¸ºæ—¥å¿—ï¼š* æ›å…‰ã€ç‚¹å‡»ã€åŠ è´­ã€è´­ä¹°ã€‚\n",
      "\n",
      "    *   **ç¬¬äºŒé˜¶æ®µï¼šæ¨èæ¼æ–—ï¼ˆâ€œå¬å› - æ’åº - é‡æ’â€ç»å…¸ç»“æ„ï¼‰ï¼š**\n",
      "\n",
      "        *   **æ­¥éª¤ 1ï¼šå¬å›ï¼ˆå¹¿æ³›ï¼‰ï¼š** éœ€è¦å¤„ç†æµ·é‡å•†å“ï¼ˆç™¾ä¸‡åˆ°åäº¿çº§ï¼‰ã€‚\n",
      "            *   *ååŒè¿‡æ»¤ (CF)ï¼š* åŸºäºç”¨æˆ·ã€åŸºäºç‰©å“ï¼ˆItem-based CFï¼‰ã€‚\n",
      "            *   *åŸºäºå†…å®¹ï¼š* æŸ¥çœ‹å•†å“ç‰¹å¾ã€‚\n",
      "            *   *å‘é‡æ£€ç´¢ï¼š* ANNï¼ˆè¿‘ä¼¼æœ€è¿‘é‚»ï¼‰æœç´¢ï¼Œä½¿ç”¨ Faiss/Milvusã€‚\n",
      "            *   *å®æ—¶é˜Ÿåˆ—ï¼š* ç”¨æˆ·åˆšåˆšçœ‹è¿‡çš„å•†å“ï¼ˆé«˜è½¬åŒ–ï¼‰ã€‚\n",
      "            *   *çƒ­é—¨/è¶‹åŠ¿ï¼š* é»˜è®¤å…œåº•ã€‚\n",
      "\n",
      "        *   **æ­¥éª¤ 2ï¼šæ’åºï¼ˆæ·±å…¥ï¼‰ï¼š** å¯¹å‰ N ä¸ªï¼ˆä¾‹å¦‚ 500-1000 ä¸ªï¼‰å€™é€‰è¿›è¡Œæ’åºã€‚\n",
      "            *   *ç²—æ’ï¼š* ç®€å•æ¨¡å‹ï¼ˆåŒå¡”ï¼‰å¿«é€Ÿè¿‡æ»¤ï¼Œå¦‚æœå¬å›é›†å¾ˆå¤§ã€‚\n",
      "            *   *ç²¾æ’ï¼š* å¤æ‚æ¨¡å‹ã€‚Wide & Deep, DIN (Deep Interest Network), DIENã€‚è¾“å‡ºï¼špCTRï¼ˆé¢„ä¼°ç‚¹å‡»ç‡ï¼‰ã€pCVRï¼ˆé¢„ä¼°è½¬åŒ–ç‡ï¼‰ã€‚\n",
      "            *   *è¯„åˆ†é€»è¾‘ï¼š* $Score = pCTR^\\alpha \\times pCVR^\\beta$ï¼ˆæ ¹æ®ä¸šåŠ¡ç›®æ ‡åŠ æƒï¼‰ã€‚\n",
      "\n",
      "        *   **æ­¥éª¤ 3ï¼šé‡æ’ï¼ˆä¸šåŠ¡é€»è¾‘ï¼‰ï¼š**\n",
      "            *   å¤šæ ·æ€§ï¼ˆMMR ç­–ç•¥ï¼‰ã€‚\n",
      "            *   å»é‡ï¼ˆå·²è´­ä¹°ç‰©å“ï¼‰ã€‚\n",
      "            *   è§„åˆ™ï¼ˆåº“å­˜æ£€æŸ¥ã€ä¿ƒé”€ï¼‰ã€‚\n",
      "\n",
      "    *   **ç¬¬ä¸‰é˜¶æ®µï¼šå®æ—¶æ¶æ„ï¼ˆLambda/Kappa æ¶æ„æ–¹æ³•ï¼‰ï¼š**\n",
      "        *   *ç¦»çº¿ (T+1)ï¼š* å…¨é‡è®­ç»ƒã€åµŒå…¥æ›´æ–°ã€‚\n",
      "        *   *å®æ—¶ (æµå¤„ç†)ï¼š* Flink/Spark Streamingã€‚\n",
      "            *   å®æ—¶ç‰¹å¾ï¼šæœ€è¿‘ 5 åˆ†é’Ÿç‚¹å‡»çš„å•†å“ã€‚\n",
      "            *   å®æ—¶æ›´æ–°ç”¨æˆ·å‘é‡ã€‚\n",
      "        *   *åœ¨çº¿ï¼š* ä½å»¶è¿ŸæœåŠ¡ï¼ˆ<50msï¼‰ã€‚\n",
      "\n",
      "    *   **å¤„ç†â€œå®æ—¶æ€§â€è¦æ±‚ï¼ˆè¯¦ç»†ï¼‰ï¼š**\n",
      "        *   *ç”¨æˆ·è¡Œä¸ºï¼š* ä½¿ç”¨ Flink æ•è·å³æ—¶ç‚¹å‡»ã€‚\n",
      "        *   *ç‰¹å¾å­˜å‚¨ï¼š* ä½¿ç”¨ Redis å­˜å‚¨å®æ—¶ç”¨æˆ·ç‰¹å¾ã€‚\n",
      "        *   *åœ¨çº¿å­¦ä¹ ï¼š*ï¼ˆé«˜çº§ï¼‰ç«‹å³ç”¨æ–°æ•°æ®æ›´æ–°æ¨¡å‹æƒé‡ï¼ˆå¯é€‰ä½†å€¼å¾—ä¸€æï¼‰ã€‚\n",
      "\n",
      "    *   **ç¬¬å››é˜¶æ®µï¼šæŠ€æœ¯æ ˆå»ºè®®ï¼š**\n",
      "        *   *æ¶ˆæ¯é˜Ÿåˆ—ï¼š* Kafka, Pulsarã€‚\n",
      "        *   *è®¡ç®—ï¼š* Spark, Flinkã€‚\n",
      "        *   *å­˜å‚¨ï¼š* HBase, Cassandra, Redisã€‚\n",
      "        *   *å‘é‡æ£€ç´¢ï¼š* Milvus, Faiss, Elasticsearchã€‚\n",
      "        *   *ML æ¡†æ¶ï¼š* TensorFlow, PyTorch, XGBoostã€‚\n",
      "        *   *æœåŠ¡ï¼š* TensorFlow Serving, TorchServeã€‚\n",
      "\n",
      "    *   **ç¬¬äº”é˜¶æ®µï¼šæŒ‡æ ‡ï¼š**\n",
      "        *   ç¦»çº¿ï¼šAUC, LogLossã€‚\n",
      "        *   åœ¨çº¿ï¼šCTR, CVR, GMV, è€—æ—¶ã€‚\n",
      "\n",
      "5.  **å®Œå–„å’Œæ¶¦è‰²ï¼š**\n",
      "    *   ç¡®ä¿æ¸…æ™°åŒºåˆ†*ç¦»çº¿*å’Œ*åœ¨çº¿*ã€‚\n",
      "    *   å¼ºè°ƒå…·ä½“è¦æ±‚ï¼šç”¨æˆ·è¡Œä¸ºã€å•†å“ç‰¹å¾ã€å®æ—¶æ€§ã€‚\n",
      "    *   ä½¿ç”¨æ ¼å¼åŒ–ï¼ˆåŠ ç²—ã€è¦ç‚¹ã€é¡¹ç›®ç¬¦å·ï¼‰ä½¿å…¶æ˜“äºé˜…è¯»ã€‚\n",
      "    *   *èµ·è‰æ—¶çš„è‡ªæˆ‘ä¿®æ­£ï¼š* æœ€åˆï¼Œæˆ‘å¯èƒ½åªæ˜¯åˆ—å‡ºç®—æ³•ã€‚æˆ‘éœ€è¦ç¡®ä¿æˆ‘æè¿°çš„æ˜¯ä¸€ä¸ª*ç³»ç»Ÿæ¶æ„*ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªç®—æ³•åˆ—è¡¨ã€‚æˆ‘éœ€è¦è°ˆè®ºæ•°æ®æµã€‚\n",
      "    *   *æ£€æŸ¥ï¼š* æˆ‘æåˆ°å‘é‡åµŒå…¥äº†å—ï¼Ÿæ˜¯çš„ï¼Œè¿™å¯¹å•†å“ç‰¹å¾è‡³å…³é‡è¦ã€‚æˆ‘æåˆ° Flink äº†å—ï¼Ÿæ˜¯çš„ï¼Œè¿™å¯¹å®æ—¶æ€§è‡³å…³é‡è¦ã€‚\n",
      "\n",
      "6.  **ç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼š**ï¼ˆè¿™ä¸ä¹‹å‰æä¾›çš„è¯¦ç»†ä¸­æ–‡å›ç­”ç›¸åŒ¹é…ã€‚ï¼‰\n",
      "\n",
      "    *   ç»“æ„ï¼š\n",
      "        1.  æ€»ä½“æ¶æ„å›¾ï¼ˆæ¦‚å¿µæ€§ï¼‰ã€‚\n",
      "        2.  æ•°æ®å±‚ï¼ˆç”»åƒï¼‰ã€‚\n",
      "        3.  ç®—æ³•å±‚ï¼ˆæ¼æ–—ï¼šå¬å› -> æ’åº -> é‡æ’ï¼‰ã€‚\n",
      "        4.  å®æ—¶æ¶æ„ï¼ˆLambda/Kappaï¼‰ã€‚\n",
      "        5.  æŠ€æœ¯æ ˆã€‚\n",
      "        6.  æŒ‡æ ‡ã€‚\n",
      "\n",
      "7.  **å¯¹ç…§ç”¨æˆ·æç¤ºè¯è¿›è¡Œæœ€ç»ˆå®¡æŸ¥ï¼š**\n",
      "    *   ç”¨æˆ·è¡Œä¸ºï¼Ÿå·²å¤„ç†ï¼ˆæ—¥å¿—ã€å®æ—¶ç‰¹å¾ï¼‰ã€‚\n",
      "    *   å•†å“ç‰¹å¾ï¼Ÿå·²å¤„ç†ï¼ˆåµŒå…¥ã€å…ƒæ•°æ®ï¼‰ã€‚\n",
      "    *   å®æ—¶æ€§ï¼Ÿå·²å¤„ç†ï¼ˆæµå¤„ç†ã€åœ¨çº¿æœåŠ¡ï¼‰ã€‚\n",
      "\n",
      "è¿™ä¸ªæ€ç»´è¿‡ç¨‹ä»ç†è§£éœ€æ±‚å¼€å§‹ï¼Œåˆ°ç»“æ„è§„åˆ’ã€è¯¦ç»†æŠ€æœ¯å¡«å……ï¼Œæœ€åæ˜¯å®¡æŸ¥å’Œæ ¼å¼åŒ–ã€‚è®¾è®¡ä¸€ä¸ªç”µå•†æ¨èç³»ç»Ÿæ¶æ„æ˜¯ä¸€ä¸ªå¤æ‚çš„å·¥ç¨‹ï¼Œéœ€è¦å¹³è¡¡**å‡†ç¡®æ€§**ã€**å®æ—¶æ€§**å’Œ**æ€§èƒ½**ã€‚é’ˆå¯¹ä½ æå‡ºçš„éœ€æ±‚ï¼ˆç”¨æˆ·è¡Œä¸ºã€å•†å“ç‰¹å¾ã€å®æ—¶æ€§ï¼‰ï¼Œæˆ‘è®¾è®¡äº†ä¸€å¥—åŸºäºç»å…¸çš„**â€œå¬å› -> æ’åº -> é‡æ’â€**æ¼æ–—æ¨¡å‹ï¼Œå¹¶ç»“åˆ**Lambdaæ¶æ„**ï¼ˆç¦»çº¿+è¿‘çº¿+åœ¨çº¿ï¼‰çš„è§£å†³æ–¹æ¡ˆã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ä¸€ã€ æ€»ä½“æ¶æ„æ¦‚è§ˆ\n",
      "\n",
      "ç³»ç»Ÿæ¶æ„ä¸»è¦åˆ†ä¸ºå››å±‚ï¼š\n",
      "1.  **æ•°æ®å±‚**ï¼šæ”¶é›†å¹¶å¤„ç†ç”¨æˆ·è¡Œä¸ºã€å•†å“å…ƒæ•°æ®å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\n",
      "2.  **è®¡ç®—å±‚**ï¼šåŒ…å«ç¦»çº¿è®­ç»ƒï¼ˆT+1ï¼‰ã€è¿‘çº¿å®æ—¶æ›´æ–°ã€åœ¨çº¿æ¨ç†ã€‚\n",
      "3.  **ç®—æ³•å±‚**ï¼šå¬å›ã€ç²—æ’ã€ç²¾æ’ã€é‡æ’ã€‚\n",
      "4.  **æœåŠ¡å±‚**ï¼šAPIç½‘å…³ã€ABæµ‹è¯•ã€åœ¨çº¿å­˜å‚¨ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### äºŒã€ è¯¦ç»†æ¶æ„è®¾è®¡\n",
      "\n",
      "#### 1. æ•°æ®é‡‡é›†ä¸å¤„ç†\n",
      "è¿™æ˜¯æ‰€æœ‰æ¨èçš„åŸºç¡€ï¼Œé‡ç‚¹åœ¨äºå¦‚ä½•å°†**ç”¨æˆ·è¡Œä¸º**å’Œ**å•†å“ç‰¹å¾**è½¬åŒ–ä¸ºæ¨¡å‹å¯ç”¨çš„æ•°æ®ã€‚\n",
      "\n",
      "*   **æ•°æ®æº**ï¼š\n",
      "    *   **ç”¨æˆ·è¡Œä¸ºæ—¥å¿—**ï¼šæ›å…‰ã€ç‚¹å‡»ã€æ”¶è—ã€åŠ è´­ã€è´­ä¹°ã€åœç•™æ—¶é•¿ã€‚ï¼ˆé€šè¿‡å®¢æˆ·ç«¯SDKæˆ–åŸ‹ç‚¹æ”¶é›†ï¼‰\n",
      "    *   **å•†å“ç‰¹å¾**ï¼šç±»ç›®ã€å“ç‰Œã€ä»·æ ¼ã€æè´¨ã€æ ‡ç­¾ã€å›¾ç‰‡ã€æ–‡æœ¬æè¿°ã€‚\n",
      "    *   **ç”¨æˆ·ç”»åƒ**ï¼šIDã€æ€§åˆ«ã€å¹´é¾„ã€åœ°ç†ä½ç½®ã€å†å²åå¥½æ ‡ç­¾ã€‚\n",
      "    *   **ä¸Šä¸‹æ–‡**ï¼šæ—¶é—´ã€èŠ‚å‡æ—¥ã€ç½‘ç»œç¯å¢ƒã€å½“å‰é¡µé¢ä½ç½®ã€‚\n",
      "\n",
      "*   **æ•°æ®æµå¤„ç†**ï¼š\n",
      "    *   **å®æ—¶æµ**ï¼šç”¨æˆ·è¡Œä¸º -> Kafka -> Flink -> å®æ—¶ç‰¹å¾åº“ï¼ˆç”¨äºå®æ—¶æ¨èï¼‰ã€‚\n",
      "    *   **ç¦»çº¿æ‰¹å¤„ç†**ï¼šå†å²æ•°æ® -> Data Warehouse (Hive/HDFS) -> ç‰¹å¾å·¥ç¨‹ -> ç¦»çº¿ç‰¹å¾å­˜å‚¨ã€‚\n",
      "\n",
      "#### 2. æ ¸å¿ƒç®—æ³•å±‚ (æ¼æ–—æ¨¡å‹)\n",
      "\n",
      "ä¸ºäº†åœ¨æµ·é‡å•†å“ä¸­å¿«é€Ÿæ‰¾åˆ°ç”¨æˆ·å–œæ¬¢çš„å•†å“ï¼Œå¿…é¡»é‡‡ç”¨å¤šçº§æ¼æ–—ç»“æ„ã€‚\n",
      "\n",
      "**A. å¬å›å±‚ - ç›®æ ‡ï¼šä»ç™¾ä¸‡çº§å•†å“ä¸­ç­›é€‰å‡ºå‡ åƒä¸ªå€™é€‰é›†**\n",
      "*   **ç­–ç•¥**ï¼šå¤šè·¯å¬å›ï¼Œç¡®ä¿å¤šæ ·æ€§ã€‚\n",
      "    *   **ååŒè¿‡æ»¤ (CF)**ï¼š\n",
      "        *   *User-based CF*ï¼šæ‰¾ç›¸ä¼¼çš„äººä¹°äº†ä»€ä¹ˆã€‚\n",
      "        *   *Item-based CF*ï¼šä¹°äº†è¿™ä¸ªå•†å“çš„äººè¿˜ä¹°äº†ä»€ä¹ˆï¼ˆåˆ©ç”¨**ç”¨æˆ·è¡Œä¸º**å…±ç°çŸ©é˜µï¼‰ã€‚\n",
      "    *   **åŸºäºå†…å®¹çš„å¬å›**ï¼š\n",
      "        *   åˆ©ç”¨**å•†å“ç‰¹å¾**ï¼ˆå¦‚ç±»ç›®ã€å“ç‰Œï¼‰è¿›è¡ŒåŒ¹é…ã€‚\n",
      "        *   åˆ©ç”¨Embeddingï¼ˆå¦‚Item2Vecæˆ–Graph embeddingï¼‰ï¼Œå°†å•†å“æ˜ å°„ä¸ºå‘é‡ï¼Œè®¡ç®—å‘é‡ç›¸ä¼¼åº¦ã€‚\n",
      "    *   **çƒ­é—¨/è¶‹åŠ¿å¬å›**ï¼šä½œä¸ºå…œåº•ï¼Œè§£å†³å†·å¯åŠ¨é—®é¢˜ã€‚\n",
      "    *   **å®æ—¶è¡Œä¸ºå¬å›**ï¼šåˆ©ç”¨Flinkå¤„ç†ç”¨æˆ·æœ€è¿‘5åˆ†é’Ÿçš„ç‚¹å‡»/åŠ è´­è¡Œä¸ºï¼Œç›´æ¥ä»ç›¸ä¼¼å•†å“åº“ä¸­æ‹‰å–ï¼ˆæ»¡è¶³**å®æ—¶æ€§è¦æ±‚**ï¼‰ã€‚\n",
      "\n",
      "**B. ç²—æ’å±‚ - ç›®æ ‡ï¼šåœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œå¿«é€Ÿå‰Šå‡å€™é€‰é›†ï¼ˆå¯é€‰ï¼‰**\n",
      "*   å¦‚æœå¬å›é›†è¿‡å¤§ï¼ˆå¦‚>5000ï¼‰ï¼Œä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼ˆå¦‚åŒå¡”æ¨¡å‹/DSSMï¼‰è¿›è¡Œå¿«é€Ÿæ‰“åˆ†ï¼Œç­›é€‰å‡ºå‰500ä¸ªè¿›å…¥ç²¾æ’ã€‚\n",
      "\n",
      "**C. ç²¾æ’å±‚ - ç›®æ ‡ï¼šå¯¹å€™é€‰å•†å“è¿›è¡Œç²¾å‡†æ’åº (CTR/CVRé¢„ä¼°)**\n",
      "*   **è¾“å…¥ç‰¹å¾**ï¼š\n",
      "    *   *ç”¨æˆ·ç‰¹å¾*ï¼šID Embedding, åå¥½ç»Ÿè®¡ã€‚\n",
      "    *   *å•†å“ç‰¹å¾*ï¼šID Embedding, ç±»ç›®, ä»·æ ¼, å›¾ç‰‡CNNç‰¹å¾ã€‚\n",
      "    *   *äº¤å‰ç‰¹å¾*ï¼šç”¨æˆ·å†å²ç±»ç›®ä¸å½“å‰å•†å“ç±»ç›®çš„åŒ¹é…åº¦ã€‚\n",
      "    *   *å®æ—¶ç‰¹å¾*ï¼šç”¨æˆ·è¿‡å»1å°æ—¶çš„ç‚¹å‡»åºåˆ—ï¼ˆRNN/Transformeræå–ï¼‰ã€‚\n",
      "*   **æ¨¡å‹é€‰æ‹©**ï¼š\n",
      "    *   Wide & Deep / DeepFM / DIN (Deep Interest Network) / DIEN (Deep Interest Evolution Network)ã€‚\n",
      "    *   å¤šç›®æ ‡å­¦ä¹ ï¼šåŒæ—¶ä¼˜åŒ–CTRï¼ˆç‚¹å‡»ç‡ï¼‰å’ŒCVRï¼ˆè½¬åŒ–ç‡ï¼‰ï¼Œä¾‹å¦‚ä½¿ç”¨ESMMæ¨¡å‹ã€‚\n",
      "\n",
      "**D. é‡æ’å±‚ - ç›®æ ‡ï¼šä¸šåŠ¡è§„åˆ™å¹²é¢„ä¸å¤šæ ·æ€§**\n",
      "*   **å»é‡**ï¼šè¿‡æ»¤æ‰ç”¨æˆ·å·²ä¹°ã€å·²åœ¨è´­ç‰©è½¦çš„å•†å“ã€‚\n",
      "*   **å¤šæ ·æ€§**ï¼šæ‰“æ•£åŒç±»å•†å“ï¼ˆé¿å…ä¸€é¡µå…¨æ˜¯æ‰‹æœºï¼‰ï¼Œä½¿ç”¨MMRï¼ˆMaximal Marginal Relevanceï¼‰ç®—æ³•ã€‚\n",
      "*   **è¿è¥å¹²é¢„**ï¼šå¼ºæ’å¹¿å‘Šã€ä½ä»·å¼•æµå“ã€åº“å­˜ä¸è¶³é™æƒã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ä¸‰ã€ å®æ—¶æ€§æ¶æ„è®¾è®¡ (Lambda/Kappa)\n",
      "\n",
      "é’ˆå¯¹ä½ æåˆ°çš„**å®æ—¶æ€§è¦æ±‚**ï¼Œå•çº¯çš„T+1ç¦»çº¿æ›´æ–°æ˜¯ä¸å¤Ÿçš„ã€‚æˆ‘ä»¬éœ€è¦å¼•å…¥è¿‘çº¿è®¡ç®—ã€‚\n",
      "\n",
      "1.  **å®æ—¶ç‰¹å¾ç®¡é“**ï¼š\n",
      "    *   ç”¨æˆ·äº§ç”Ÿè¡Œä¸ºï¼ˆç‚¹å‡»ï¼‰ã€‚\n",
      "    *   Kafka æ¶ˆæ¯é˜Ÿåˆ—æ¥æ”¶ã€‚\n",
      "    *   Flink æ¶ˆè´¹ Kafkaï¼Œå®æ—¶æ›´æ–°ç”¨æˆ·çš„çŸ­æœŸå…´è¶£ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼šæ›´æ–° Redis ä¸­çš„â€œç”¨æˆ·æœ€è¿‘ç‚¹å‡»çš„10ä¸ªå•†å“â€åˆ—è¡¨ï¼‰ã€‚\n",
      "    *   **æ•ˆæœ**ï¼šå½“ç”¨æˆ·åˆ·æ–°é¦–é¡µæ—¶ï¼Œç²¾æ’æ¨¡å‹èƒ½è¯»å–åˆ°ç”¨æˆ·1åˆ†é’Ÿå‰åˆšçœ‹è¿‡çš„å•†å“ç‰¹å¾ï¼Œä»è€Œè°ƒæ•´æ¨èç»“æœã€‚\n",
      "\n",
      "2.  **åœ¨çº¿å­¦ä¹ **ï¼š\n",
      "    *   å¯¹äºé«˜é¢‘åœºæ™¯ï¼Œå¯ä»¥ä½¿ç”¨ Flink + åœ¨çº¿å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚ TensorFlow Extended æˆ– Alinkï¼‰ï¼Œåˆ©ç”¨å®æ—¶åé¦ˆæµä¸æ–­å¾®è°ƒæ¨¡å‹å‚æ•°ï¼Œå®ç°æ¨¡å‹çš„åˆ†é’Ÿçº§/å°æ—¶çº§æ›´æ–°ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### å››ã€ ç³»ç»ŸæŠ€æœ¯æ ˆæ¨è\n",
      "\n",
      "| æ¨¡å— | æŠ€æœ¯ç»„ä»¶é€‰å‹ (ç¤ºä¾‹) |\n",
      "| :--- | :--- |\n",
      "| **æ¶ˆæ¯é˜Ÿåˆ—** | Apache Kafka (æ—¥å¿—æ”¶é›†), Pulsar |\n",
      "| **æµå¼è®¡ç®—** | Apache Flink (å®æ—¶ç‰¹å¾å¤„ç†ã€å®æ—¶å¬å›) |\n",
      "| **æ‰¹å¤„ç†/æ•°ä»“** | Apache Spark, Hive, Presto/ClickHouse (OLAPåˆ†æ) |\n",
      "| **åœ¨çº¿å­˜å‚¨** | Redis (ç”¨æˆ·ç”»åƒã€å®æ—¶ç‰¹å¾), Elasticsearch (å€’æ’ç´¢å¼•), Cassandra/HBase |\n",
      "| **å‘é‡æ£€ç´¢** | Milvus, Faiss (ç”¨äºEmbeddingç›¸ä¼¼åº¦æ£€ç´¢) |\n",
      "| **è®­ç»ƒæ¡†æ¶** | TensorFlow, PyTorch, XGBoost |\n",
      "| **æ¨¡å‹æœåŠ¡** | TensorFlow Serving, TorchServe, Triton Inference Server |\n",
      "\n",
      "---\n",
      "\n",
      "### äº”ã€ å…³é”®æ•°æ®æµè½¬ç¤ºä¾‹\n",
      "\n",
      "**åœºæ™¯ï¼šç”¨æˆ·Aåˆšåœ¨â€œæ‰‹æœºâ€åˆ†ç±»æµè§ˆäº† iPhone 15ï¼Œå¹¶åŠ å…¥è´­ç‰©è½¦ï¼Œéšå³åˆ·æ–°é¦–é¡µæ¨èæµã€‚**\n",
      "\n",
      "1.  **è¡Œä¸ºæ•è·**ï¼šå®¢æˆ·ç«¯ä¸ŠæŠ¥ `add_to_cart` äº‹ä»¶åˆ° Kafkaã€‚\n",
      "2.  **è¿‘çº¿å¤„ç† (æ¯«ç§’çº§)**ï¼š\n",
      "    *   Flink æ¶ˆè´¹è¯¥æ¶ˆæ¯ï¼Œæå– `user_id=A`, `item_id=iPhone15`ã€‚\n",
      "    *   æ›´æ–° Redis ä¸­ User A çš„ `last_clicked_items` é˜Ÿåˆ—å’Œ `preference_category`ï¼ˆå¢åŠ æ‰‹æœºç±»ç›®æƒé‡ï¼‰ã€‚\n",
      "3.  **ç”¨æˆ·è¯·æ±‚**ï¼š\n",
      "    *   å®¢æˆ·ç«¯è¯·æ±‚æ¨èæ¥å£ã€‚\n",
      "    *   **å¬å›é˜¶æ®µ**ï¼š\n",
      "        *   *CFå¬å›*ï¼šæŸ¥æ‰¾ä¹°äº† iPhone 15 çš„äººè¿˜ä¹°äº†ä»€ä¹ˆï¼ˆæ‰‹æœºå£³ã€AirPodsï¼‰ã€‚\n",
      "        *   *å‘é‡å¬å›*ï¼šåˆ©ç”¨ iPhone 15 çš„ Embedding æ£€ç´¢ç›¸ä¼¼å•†å“ã€‚\n",
      "        *   *å®æ—¶å¬å›*ï¼šæ ¹æ® User A åˆšæ›´æ–°çš„â€œæ‰‹æœºç±»ç›®åå¥½â€ï¼Œæ£€ç´¢çƒ­é—¨æ‰‹æœºé…ä»¶ã€‚\n",
      "    *   **æ’åºé˜¶æ®µ**ï¼š\n",
      "        *   æ¨¡å‹ä» Redis è¯»å– User A çš„å®æ—¶ç‰¹å¾ï¼ˆåˆšçœ‹è¿‡ iPhone 15ï¼‰ã€‚\n",
      "        *   æ¨¡å‹é¢„æµ‹â€œæ‰‹æœºå£³â€çš„ CTR ä¼šæ¯”â€œè¿è¡£è£™â€é«˜ã€‚\n",
      "4.  **ç»“æœè¿”å›**ï¼š\n",
      "    *   é‡æ’è°ƒæ•´é¡ºåºï¼Œç¡®ä¿å‰æ’æ˜¯ iPhone 15 çš„ç›¸å…³é…ä»¶ã€‚\n",
      "    *   è¿”å›ç»™ç”¨æˆ·ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### å…­ã€ æ€»ç»“ä¸ä¼˜åŒ–å»ºè®®\n",
      "\n",
      "1.  **å†·å¯åŠ¨**ï¼š\n",
      "    *   åˆ©ç”¨**å•†å“ç‰¹å¾**ï¼ˆå†…å®¹ï¼‰è¿›è¡Œæ¨èã€‚\n",
      "    *   åˆ©ç”¨ Explore-Exploit (Banditç®—æ³•) æ¢ç´¢æ–°ç”¨æˆ·å…´è¶£ã€‚\n",
      "2.  **è¯„ä¼°ä½“ç³»**ï¼š\n",
      "    *   **ç¦»çº¿è¯„ä¼°**ï¼šAUC, LogLossã€‚\n",
      "    *   **åœ¨çº¿è¯„ä¼°**ï¼šA/B Testing (CTR, CVR, GMV, äººå‡åœç•™æ—¶é•¿)ã€‚\n",
      "3.  **æ€§èƒ½ä¼˜åŒ–**ï¼š\n",
      "    *   å¬å›é˜¶æ®µå¹¶å‘æ‰§è¡Œã€‚\n",
      "    *   é«˜é¢‘ç‰¹å¾ç¼“å­˜ã€‚\n",
      "    *   æ¨¡å‹å‰ªææˆ–é‡åŒ–ï¼ˆå¦‚FP16è½¬INT8ï¼‰ä»¥åŠ é€Ÿæ¨ç†ã€‚\n",
      "\n",
      "è¿™ä¸ªæ¶æ„æ¶µç›–äº†ä»æ•°æ®æ‘„å…¥ã€å®æ—¶å¤„ç†ã€æ¨¡å‹è®­ç»ƒåˆ°åœ¨çº¿æœåŠ¡çš„å…¨é“¾è·¯ï¼Œèƒ½å¤Ÿå……åˆ†åˆ©ç”¨ç”¨æˆ·è¡Œä¸ºå’Œå•†å“ç‰¹å¾ï¼ŒåŒæ—¶æ»¡è¶³ç”µå•†åœºæ™¯å¯¹å®æ—¶æ€§çš„ä¸¥è‹›è¦æ±‚ã€‚"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# åˆ›å»ºæµå¼æ·±åº¦æ€è€ƒè¯·æ±‚\n",
    "response = zhipu_client.chat.completions.create(\n",
    "    model=\"glm-4.7\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"è®¾è®¡ä¸€ä¸ªç”µå•†ç½‘ç«™çš„æ¨èç³»ç»Ÿæ¶æ„ï¼Œè€ƒè™‘ç”¨æˆ·è¡Œä¸ºã€å•†å“ç‰¹å¾å’Œå®æ—¶æ€§è¦æ±‚\"}\n",
    "    ],\n",
    "    thinking={\n",
    "        \"type\": \"enabled\"  # å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼\n",
    "    },\n",
    "    stream=True,  # å¯ç”¨æµå¼è¾“å‡º\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "# å¤„ç†æµå¼å“åº”\n",
    "reasoning_content = \"\"\n",
    "thinking_phase = True\n",
    "\n",
    "for chunk in response:\n",
    "    if not chunk.choices:\n",
    "        continue\n",
    "    \n",
    "    delta = chunk.choices[0].delta\n",
    "    \n",
    "    # å¤„ç†æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "    if hasattr(delta, 'reasoning_content') and delta.reasoning_content:\n",
    "        reasoning_content += delta.reasoning_content\n",
    "        if thinking_phase:\n",
    "            print(\"ğŸ§  æ€è€ƒä¸­...\", end=\"\", flush=True)\n",
    "            thinking_phase = False\n",
    "        print(delta.reasoning_content, end=\"\", flush=True)\n",
    "    \n",
    "    # å¤„ç†å›ç­”å†…å®¹\n",
    "    if hasattr(delta, 'content') and delta.content:\n",
    "        if thinking_phase:\n",
    "            print(\"\\n\\nğŸ’¡ å›ç­”:\")\n",
    "            thinking_phase = False\n",
    "        print(delta.content, end=\"\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5352e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1d1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
